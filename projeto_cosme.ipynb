{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def open_sheet(sheet_name):\n",
    "    return pd.read_excel(sheet_name)\n",
    "\n",
    "def alterar_coluna_dataHora(dataframe):\n",
    "    dataframe = dataframe.astype({'Hora':'string'})\n",
    "    print(\"Alterou Type\")\n",
    "    for x in range(len(dataframe)):\n",
    "        value=dataframe.loc[x,\"Datahora\"]\n",
    "        split=value.split(\":\")\n",
    "        dataframe.loc[x,'Datahora'] = split[0]\n",
    "        dataframe.loc[x,\"Mês\"]=split[1].lstrip('0')\n",
    "        dataframe.loc[x,'Hora'] = value.split(\" \")[1]\n",
    "    return dataframe\n",
    "\n",
    "def alterar_coluna_dia(dataframe):\n",
    "    dataframe = dataframe.astype({'Dia':'string'})\n",
    "    print(\"Antes do for\")\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        val = dataframe.loc[i,'Dia']\n",
    "        i_dia = val.split(' ')[0].split('-')[2]\n",
    "        dataframe.loc[i,'Dia'] = i_dia\n",
    "    print(\"Depois do for\")\n",
    "    return dataframe\n",
    "\n",
    "def get_1000_de_cada_file(df_files):\n",
    "    all_df=[]\n",
    "    for df_year in df_files:\n",
    "        print(\"Novo ano\")\n",
    "        total_lines = df_year.shape[0]\n",
    "        all_df_year = []\n",
    "        for j in range(1,13):\n",
    "            df_month = df_year[df_year['Mês']==str(j)]\n",
    "            perc_total_amostra = df_month.shape[0]/total_lines\n",
    "            print(\"Mês \"+str(j)+\" Percentagem: \"+str(perc_total_amostra))\n",
    "            print(int(perc_total_amostra*1000)+1)\n",
    "            all_df_year.append(df_month.sample(n = int(perc_total_amostra*1000)+1))\n",
    "        all_df.append(pd.concat(all_df_year))\n",
    "    return pd.concat(all_df)\n",
    "\n",
    "def get_sample():\n",
    "    df_files = []\n",
    "    for i in range(10):\n",
    "        name = \"201\"+str(i)+\"Acidentes.xlsx\"\n",
    "        print(\"File: \"+name)\n",
    "        df_temp = open_sheet(name)\n",
    "        df_files.append(alterar_coluna_dataHora(df_temp))\n",
    "    df_excel = get_1000_de_cada_file(df_files)\n",
    "    df_excel = df_excel.rename(columns = {'Datahora':'Ano'}, inplace = False)\n",
    "    df_excel.to_excel(\"10000_sample_sem_transformacao.xlsx\")\n",
    "\n",
    "def mostrar_distribuicao_temporal():\n",
    "    df_2010=open_sheet(\"2010Acidentes.xlsx\")\n",
    "    print(\"Antes for\")\n",
    "    total_lines = df_2010.shape[0]\n",
    "    for x in range(total_lines):\n",
    "        value=df_2010.loc[x,\"Datahora\"]\n",
    "        split=value.split(\":\")[1]\n",
    "        df_2010.loc[x,\"Mês\"]=split.lstrip('0')\n",
    "    all_df_year = []\n",
    "    list_percen = []\n",
    "    for j in range(1,13):\n",
    "        df_month = df_2010[df_2010['Mês']==str(j)]\n",
    "        perc_total_amostra = df_month.shape[0]/total_lines\n",
    "        list_percen.append(perc_total_amostra)\n",
    "        all_df_year.append(df_month.sample(n = int(perc_total_amostra*1000)+1))\n",
    "    df_res = pd.concat(all_df_year)\n",
    "    list_percen_after = []\n",
    "    for j in range(1,13):\n",
    "        df_month = df_res[df_res['Mês']==str(j)]\n",
    "        perc_total_amostra = df_month.shape[0]/df_res.shape[0]\n",
    "        list_percen_after.append(perc_total_amostra)\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    ax1 = fig.add_subplot(2, 2, 1)\n",
    "    ax1.plot(df_2010['Mês'].unique().astype(int),list_percen)\n",
    "    ax1.set_title(\"Antes de reduzir\")\n",
    "    plt.legend([\"n=\"+str(total_lines)])\n",
    "    ax2 = fig.add_subplot(2, 2, 2)\n",
    "    ax2.plot(df_res['Mês'].unique().astype(int),list_percen_after)\n",
    "    ax2.set_title(\"Depois de reduzir\")\n",
    "    plt.legend([\"n=\"+str(df_res.shape[0])])\n",
    "    plt.show()\n",
    "    print(\"Antes de reduzir: \\n\"+str(list_percen))\n",
    "    print(\"Depois de reduzir: \\n\"+str(list_percen_after))\n",
    "    return df_res\n",
    "\n",
    "# teste()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "features_para_remover = [\"Id. Acidente\",\"Dia\",\"Entidades Fiscalizadoras\",\"Latitude GPS\",\n",
    "                         \"Longitude GPS\",\"Freguesia\",\"Pov. Proxima\",\"Nome arruamento\",\"Km\"]\n",
    "filename = \"sample_features_removidas.xlsx\"\n",
    "df = open_sheet(filename)\n",
    "\n",
    "\n",
    "def delete_Freguesia_e_concelhos_duplicados(df_nuts,CONCELHO):\n",
    "    del df_nuts['FREGUESIA']\n",
    "    df_nuts = df_nuts.drop_duplicates(subset=[CONCELHO], keep='first')\n",
    "    return df_nuts\n",
    "\n",
    "def replace_specials_chars():\n",
    "    df_nuts = open_sheet('nuts_II.xlsx')\n",
    "    CONCELHO = \"CONCELHO\"\n",
    "    old_chars = ['ç','Ç','é','É','ã','Ã','ê','Ê','á','à','Á','À','Ô','ô','ó','ú','Í','í','â','Â','Ó']\n",
    "    new_chars = ['c','C','e','E','a','A','e','E','a','a','A','A','O','o','o','u','I','i','a','A','O']\n",
    "\n",
    "    col_str = df_nuts[CONCELHO].str\n",
    "    for i in range(len(old_chars)):\n",
    "        if col_str.contains(old_chars[i]).sum() > 0:\n",
    "            df_nuts[CONCELHO] = df_nuts[CONCELHO].str.replace(old_chars[i],new_chars[i])\n",
    "    df_nuts.to_excel('nuts_II.xlsx')\n",
    "    return df_nuts[CONCELHO].value_counts()\n",
    "\n",
    "\n",
    "def remover_features(df_rem):\n",
    "    df_rem = df_rem.drop(df_rem.columns[[0]], axis=1)\n",
    "    for f in features_para_remover:\n",
    "        del df_rem[f]\n",
    "    return df_rem\n",
    "\n",
    "def groupBy_each_feature():\n",
    "    results=[]\n",
    "    for col in df.columns:\n",
    "        t = \"Feature \"+str(col),df[col].value_counts()\n",
    "        results.append(t)\n",
    "    return results\n",
    "\n",
    "def replace_concelhos_especificos(concelho):\n",
    "    if concelho == 'Sobral Monte Agraco':\n",
    "        return 'Sobral de Monte Agraco'\n",
    "    elif concelho == 'Freixo Espada a Cinta':\n",
    "        return 'Freixo de Espada a Cinta'\n",
    "    elif concelho == 'Lagoa (Algarve)':\n",
    "        return 'Lagoa'\n",
    "    elif concelho == \"Obidos\":\n",
    "        return 'obidos'\n",
    "    return concelho\n",
    "\n",
    "\n",
    "def obter_regioes_nuts_II(df_regioes):\n",
    "    CONCELHO = \"CONCELHO\"\n",
    "    nuts_II_lista = open_sheet(\"nuts_II.xlsx\")\n",
    "    for i in range(df_regioes.shape[0]):\n",
    "        concelho = df_regioes.loc[i,\"Concelho\"]\n",
    "        concelho = replace_concelhos_especificos(concelho)\n",
    "        index_nuts_II_lista = nuts_II_lista.index[nuts_II_lista[CONCELHO] == concelho].tolist()\n",
    "        if len(index_nuts_II_lista) > 0:\n",
    "            val = nuts_II_lista.loc[index_nuts_II_lista[0],'NUTS II']\n",
    "            df_regioes.loc[i,'Distrito'] = val\n",
    "        else:\n",
    "            print(\"Concelho não detetado: \"+str(concelho))\n",
    "    df_regioes = df_regioes.rename(columns = {'Distrito':'NUTS II'}, inplace = False)\n",
    "    return df_regioes\n",
    "\n",
    "\n",
    "def check_if_nuts_is_rigth():\n",
    "    CONCELHO = \"CONCELHO\"\n",
    "    df_nuts = open_sheet('nuts_II.xlsx')\n",
    "    certos = 0\n",
    "    errados = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        concelho = df.loc[i,\"Concelho\"]\n",
    "        concelho = replace_concelhos_especificos(concelho)\n",
    "        index = df_nuts.index[df_nuts[CONCELHO] == concelho].tolist()\n",
    "        df_val = df.loc[i,'NUTS II']\n",
    "        df_nuts_val = df_nuts.loc[index[0],'NUTS II']\n",
    "        if df_val == df_nuts_val:\n",
    "            certos+=1\n",
    "        else:\n",
    "            errados+=1\n",
    "    print(\"Certos: \"+str(certos) + \" Errados: \"+str(errados))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "def discretize_velocidade_geral_e_local(dataframe):\n",
    "    dataframe = dataframe.loc[dataframe['Velocidade geral'] != 0]\n",
    "    dataframe.reset_index(inplace=True)\n",
    "    for x in range(dataframe.shape[0]):\n",
    "        vel_local = dataframe.loc[x,'Velocidade local']\n",
    "        vel_geral = dataframe.loc[x,'Velocidade geral']\n",
    "\n",
    "        if vel_local < 50.0: nova_vel_local = \"5.0 - 45.0\"\n",
    "        elif 50 < vel_local < 90.0: nova_vel_local = \"60.0 - 80.0\"\n",
    "        elif 90.0 < vel_local: nova_vel_local = \"100.0 - 120.0\"\n",
    "        else: nova_vel_local = str(vel_local)\n",
    "\n",
    "        if vel_geral < 50.0: nova_vel_geral = \"10.0 - 40.0\"\n",
    "        elif 50 < vel_geral < 90.0: nova_vel_geral = \"60.0 - 80.0\"\n",
    "        elif 90.0 < vel_geral: nova_vel_geral = \"100.0 - 120.0\"\n",
    "        else: nova_vel_geral = str(vel_geral)\n",
    "\n",
    "        dataframe.loc[x,'Velocidade local'] = nova_vel_local\n",
    "        dataframe.loc[x,'Velocidade geral'] = nova_vel_geral\n",
    "    n = dataframe\n",
    "    return n\n",
    "\n",
    "\n",
    "def changeEstacoesTempo(df_estacoes):\n",
    "    for x in range(len(df_estacoes)):\n",
    "        # print(x)\n",
    "        value=int(df_estacoes.loc[x,\"Mês\"])\n",
    "        if 4 <= value <= 6:\n",
    "            estacao=\"Primavera\"\n",
    "        elif 7 <= value <= 9:\n",
    "            estacao=\"Verão\"\n",
    "        elif 10 <= value <= 12:\n",
    "            estacao=\"Outono\"\n",
    "        else:\n",
    "            estacao=\"Inverno\"\n",
    "        df_estacoes.loc[x,\"Mês\"]=estacao\n",
    "    # df.to_excel(\"temp_\"+str(filename))\n",
    "    df_estacoes = df_estacoes.rename(columns = {'Mês':'Estação do Ano'}, inplace = False)\n",
    "    return df_estacoes\n",
    "\n",
    "def check_estacoes_tempo():\n",
    "    df_old = open_sheet('10000_sample.xlsx')\n",
    "    df_temp = open_sheet('temp_10000_sample_features_removidas.xlsx')\n",
    "    return df_old['Mês'].value_counts(),df_temp['Mês'].value_counts()\n",
    "\n",
    "def calcPartofDay(m,a,n,hour):\n",
    "    if m<=hour<a:\n",
    "        part_of_day=\"Manhã\"\n",
    "    elif a<=hour<n:\n",
    "        part_of_day=\"Tarde\"\n",
    "    else:\n",
    "        part_of_day=\"Noite\"\n",
    "    return part_of_day\n",
    "\n",
    "def changeToMorning_Afternoon_Night(df_horas):\n",
    "    horas = []\n",
    "    for x in range(len(df_horas)):\n",
    "        # print(x)\n",
    "        station=(df_horas.loc[x,\"Estação do Ano\"])\n",
    "        hourC=(df_horas.loc[x,\"Hora\"])\n",
    "        hour=int(hourC.split(\":\")[0])\n",
    "        if station==\"Primavera\":\n",
    "            part_of_day= calcPartofDay(6,13,20,hour)\n",
    "        elif station==\"Verão\":\n",
    "            part_of_day= calcPartofDay(6,13,21,hour)\n",
    "        elif station==\"Outono\":\n",
    "            part_of_day= calcPartofDay(8,13,18,hour)\n",
    "        else:\n",
    "            part_of_day= calcPartofDay(8,13,17,hour)\n",
    "        # print(part_of_day)\n",
    "        df_horas.loc[x,\"Hora\"]=part_of_day\n",
    "        horas.append(hour)\n",
    "    # df_horas['Hora Int'] = horas\n",
    "    # df_horas.to_excel(\"temp_\"+str(filename))\n",
    "    return df_horas\n",
    "\n",
    "def transformar_feridosGraves_numMortos_feridosLigeiros(df_feridos_mortos):\n",
    "    for x in range(df_feridos_mortos.shape[0]):\n",
    "        num_feridos_graves = df_feridos_mortos.loc[x,'Num. Feridos graves a 30 dias']\n",
    "        num_mortos = df_feridos_mortos.loc[x,'Num. Mortos a 30 dias']\n",
    "        num_feridos_ligeiros = df_feridos_mortos.loc[x,'Num. Feridos ligeiros a 30 dias']\n",
    "        if num_feridos_graves > 0: houve_ou_nao_feridos_graves = \"Houve feridos graves\"\n",
    "        else: houve_ou_nao_feridos_graves = \"Não houve feridos graves\"\n",
    "\n",
    "        if num_mortos > 0: houve_ou_nao_mortos = \"Houve mortos\"\n",
    "        else: houve_ou_nao_mortos = \"Não houve mortos\"\n",
    "\n",
    "        new_num_feridos_ligeiros = num_feridos_ligeiros\n",
    "        if num_feridos_ligeiros > 3: new_num_feridos_ligeiros = 4\n",
    "\n",
    "        df_feridos_mortos.loc[x,'Num. Feridos graves a 30 dias'] = houve_ou_nao_feridos_graves\n",
    "        df_feridos_mortos.loc[x,'Num. Mortos a 30 dias'] = houve_ou_nao_mortos\n",
    "        df_feridos_mortos.loc[x,'Num. Feridos ligeiros a 30 dias'] = new_num_feridos_ligeiros\n",
    "\n",
    "    return df_feridos_mortos\n",
    "\n",
    "def agregar_dias_da_semana(df_dias):\n",
    "    for x in range(len(df_dias)):\n",
    "        # if x == 10 or x==500 or x==1000 or x==2000 or x==5000 or x==7500: print(x)\n",
    "        dia_de_sem = df_dias.loc[x,'Dia da Semana']\n",
    "        hora = df_dias.loc[x,'Hora']\n",
    "        if dia_de_sem.__contains__(\"Sábado\") or dia_de_sem.__contains__(\"Domingo\") or (dia_de_sem.__contains__(\"Sexta\") and not hora.__contains__(\"Manhã\")):\n",
    "            new_dia = \"Fim de semana\"\n",
    "        else:\n",
    "            new_dia = \"Dia útil\"\n",
    "        df_dias.loc[x,'Dia da Semana'] = new_dia\n",
    "    return df_dias\n",
    "\n",
    "def juntar_cond_aderencia(df_cond):\n",
    "    for x in range(df_cond.shape[0]):\n",
    "        cond_aderencia = df_cond.loc[x,'Cond Aderência']\n",
    "        new_cond = cond_aderencia\n",
    "        if not cond_aderencia.__contains__(\"Seco e limpo\") and not cond_aderencia.__contains__(\"Molhado\") and not cond_aderencia.__contains__(\"Húmido\") and not cond_aderencia.__contains__(\"NÃO DEFINIDO\"):\n",
    "            new_cond = \"Outra substância\"\n",
    "\n",
    "        df_cond.loc[x,'Cond Aderência'] = new_cond\n",
    "    return df_cond\n",
    "\n",
    "def juntar_fatores_atmosfericos(df_fatores):\n",
    "    for x in range(df_fatores.shape[0]):\n",
    "        fatores = df_fatores.loc[x,'Factores Atmosféricos']\n",
    "        novo_fator=fatores\n",
    "        if not fatores.__contains__('Bom tempo') and not fatores.__contains__('Chuva') and not fatores.__contains__(\"NÃO DEFINIDO\"):\n",
    "            novo_fator = \"Outro\"\n",
    "        df_fatores.loc[x,'Factores Atmosféricos'] = novo_fator\n",
    "    return df_fatores\n",
    "\n",
    "def juntar_luminosidade(df_lum):\n",
    "    for x in range(df_lum.shape[0]):\n",
    "        lum = df_lum.loc[x,'Luminosidade']\n",
    "        novo_lum = lum\n",
    "        if lum.__contains__('Aurora ou crepúsculo') or lum.__contains__('Sol escandeante'):\n",
    "            novo_lum = \"Outras condições\"\n",
    "        df_lum.loc[x,'Luminosidade'] = novo_lum\n",
    "    return df_lum\n",
    "\n",
    "def juntar_interseccao_vias(df_inter):\n",
    "    for x in range(df_inter.shape[0]):\n",
    "        inter = df_inter.loc[x,'Intersecção Vias']\n",
    "        novo_inter = inter\n",
    "        if inter.__contains__('Em via de desaceleração') or inter.__contains__('Em ramo de ligação - saída'):\n",
    "            novo_inter = \"Desaceleração/Saída\"\n",
    "        elif inter.__contains__('Em via de aceleração') or inter.__contains__('Em ramo de ligação - entrada'):\n",
    "            novo_inter = \"Aceleração/Entrada\"\n",
    "        elif inter.__contains__('Em entroncamento') or inter.__contains__('Em cruzamento'):\n",
    "            novo_inter = \"Entroncamento/Cruzamento\"\n",
    "        df_inter.loc[x,'Intersecção Vias'] = novo_inter\n",
    "    return df_inter\n",
    "\n",
    "def changeTypeOfNature(df_natu):\n",
    "    for x in range(len(df_natu)):\n",
    "        natureza=(df_natu.loc[x,\"Natureza\"])\n",
    "        splited=natureza.split(\" \")[0]\n",
    "        df_natu.loc[x,\"Natureza\"]=splited\n",
    "    return df_natu\n",
    "\n",
    "\n",
    "def check_periodos_do_dia(estacao):\n",
    "    df_temp = open_sheet('temp_10000_sample_features_removidas.xlsx')\n",
    "    df_temp_estacao = df_temp[df_temp['Mês'] == estacao]\n",
    "    return df_temp_estacao['Hora Int'].value_counts(),df_temp_estacao['Hora'].value_counts()\n",
    "\n",
    "def remover_colunas_Unnamed(name):\n",
    "    df_unnamed = open_sheet(name)\n",
    "    for col in df_unnamed.columns:\n",
    "        if \"Unnamed\" in col:\n",
    "            del df_unnamed[col]\n",
    "    df_unnamed.to_excel(name)\n",
    "\n",
    "def remove_given_features(name,list_of_features):\n",
    "    df_temp = open_sheet(name)\n",
    "    for f in list_of_features:\n",
    "        del df_temp[f]\n",
    "    df_temp.to_excel('final.xlsx')\n",
    "\n",
    "\n",
    "def criar_novo_ficheiro_com_dados_transformados(name):\n",
    "    dataframe = open_sheet(name)\n",
    "    dataframe = changeEstacoesTempo(dataframe)\n",
    "    print(\"estacao\")\n",
    "    dataframe = changeToMorning_Afternoon_Night(dataframe)\n",
    "    print(\"horas\")\n",
    "    dataframe = discretize_velocidade_geral_e_local(dataframe)\n",
    "    print(\"velocidade\")\n",
    "    dataframe = agregar_dias_da_semana(dataframe)\n",
    "    print(\"dias\")\n",
    "    dataframe = transformar_feridosGraves_numMortos_feridosLigeiros(dataframe)\n",
    "    print(\"feridos\")\n",
    "    dataframe = juntar_cond_aderencia(dataframe)\n",
    "    print(\"cond aderencia\")\n",
    "    dataframe = obter_regioes_nuts_II(dataframe)\n",
    "    print(\"nuts\")\n",
    "    dataframe = juntar_fatores_atmosfericos(dataframe)\n",
    "    print(\"fatores\")\n",
    "    dataframe = juntar_luminosidade(dataframe)\n",
    "    print(\"lum\")\n",
    "    dataframe = juntar_interseccao_vias(dataframe)\n",
    "    print(\"vias\")\n",
    "    dataframe = changeTypeOfNature(dataframe)\n",
    "    print(\"natureza\")\n",
    "    dataframe.to_excel(\"transformado_\"+name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "def get_frequencias_dos_valores(df_temp,col):\n",
    "    values = df_temp[col].unique()\n",
    "    print(str(col) +\" values \" +str(values))\n",
    "    total_lines = df_temp.shape[0]\n",
    "    print(\" Total lines: \"+str(total_lines))\n",
    "    frequencias = []\n",
    "    for v in values:\n",
    "        v_total = df_temp[df_temp[col] == v].shape[0]\n",
    "        print(\" \"+str(v)+\": \"+str(v_total))\n",
    "        frequencias.append((v,v_total/total_lines))\n",
    "    return frequencias,col\n",
    "\n",
    "def frequencias_do_num_a_30_dias(df_temp):\n",
    "    return get_frequencias_dos_valores(df_temp,\"Num. Mortos a 30 dias\"),get_frequencias_dos_valores(df_temp,\"Num. Feridos graves a 30 dias\"),\\\n",
    "        get_frequencias_dos_valores(df_temp,\"Num. Feridos ligeiros a 30 dias\")\n",
    "\n",
    "\n",
    "def frequencias_do_num_a_30_dias_com_novas_colunas(df_temp):\n",
    "    return get_frequencias_dos_valores(df_temp,\"Houve Mortos a 30 dias\"),get_frequencias_dos_valores(df_temp,\"Houve Feridos graves a 30 dias\"),\\\n",
    "        get_frequencias_dos_valores(df_temp,\"Novo Num. Feridos ligeiros a 30 dias\")\n",
    "\n",
    "\n",
    "def check_se_feature_afeta_distribuicao():\n",
    "    # df_temp = open_sheet('10000_sample.xlsx')\n",
    "    # df_temp = open_sheet(filename)\n",
    "    df_temp = open_sheet('final.xlsx')\n",
    "    frequencias = frequencias_do_num_a_30_dias_com_novas_colunas(df_temp)\n",
    "\n",
    "    # col = 'Mês'\n",
    "    col = 'New Intersecção Vias'\n",
    "    val = \"Em passagem de nível\"\n",
    "    # val = 3\n",
    "    # filter_df = df_temp[df_temp[col] == val]\n",
    "    # filter_df = df_temp[df_temp[col].str.contains(val)]\n",
    "    filter_df = df_temp[df_temp['Velocidade geral'] < df_temp['Velocidade local']]\n",
    "    check_se_col_value_afeta_distribuicao(filter_df,frequencias,val,col)\n",
    "\n",
    "def addlabels(x,y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(x[i],y[i],str(round(y[i], 4)))\n",
    "\n",
    "def check_se_col_value_afeta_distribuicao(filter_df,frequencias, val, col):\n",
    "    frequencias_col_value = frequencias_do_num_a_30_dias_com_novas_colunas(filter_df)\n",
    "\n",
    "    for i in range(len(frequencias)):\n",
    "        f_frequencias = list(zip(*frequencias[i][0]))\n",
    "        col_value_frequencias = list(zip(*frequencias_col_value[i][0]))\n",
    "        fig = plt.figure(figsize = (10,10))\n",
    "        ax1 = fig.add_subplot(2, 2, 1)\n",
    "        ax1.bar(f_frequencias[0],f_frequencias[1])\n",
    "        ax1.set_title(\"Original | \"+str(frequencias[i][1]))\n",
    "        plt.legend([str(col)+ \" \"+str(val)])\n",
    "        plt.ylim((0,1.1))\n",
    "        addlabels(f_frequencias[0],f_frequencias[1])\n",
    "        ax2 = fig.add_subplot(2, 2, 2)\n",
    "        ax2.bar(col_value_frequencias[0],col_value_frequencias[1])\n",
    "        plt.legend([str(col)+ \" \"+str(val)])\n",
    "        plt.ylim((0,1.1))\n",
    "        addlabels(col_value_frequencias[0],col_value_frequencias[1])\n",
    "        ax2.set_title(\"Filtrado | \"+str(frequencias_col_value[i][1]))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "def feature_is_seasonal(df_temp,col,col1):\n",
    "    confusion_matrix = pd.crosstab(df_temp[col],df_temp[col1])\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2/n\n",
    "    r,k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2-((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r-((r-1)**2)/(n-1)\n",
    "    kcorr = k-((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr/min((kcorr-1),(rcorr-1)))\n",
    "\n",
    "# def seasonal(df_sea,col):\n",
    "#     total_lines_4_estacoes = df_sea.shape[0]\n",
    "#     values = df_sea[col].unique()\n",
    "#     result = []\n",
    "#     for v in values:\n",
    "\n",
    "\n",
    "def calculate_correlations(df_corr):\n",
    "    features_to_check = ['Hora','Velocidade geral', 'Velocidade local','Dia da Semana','Num. Mortos a 30 dias','Num. Feridos graves a 30 dias','Num. Feridos ligeiros a 30 dias',\t'Características Tecnicas1',\t'Cond Aderência',\t'NUTS II','Tipos Vias',\t'Estado Conservação','Factores Atmosféricos','Reg Circulação1',\t'Intersecção Vias',\t'Localizações',\t'Luminosidade','Marca Via',\t'Natureza','Tipo Piso',\t'Traçado 1',\t'Traçado 2',\t'Traçado 3',\t'Traçado 4',\t'Via Trânsito']\n",
    "\n",
    "    for f in features_to_check:\n",
    "        corr = feature_is_seasonal(df_corr,'Estação do Ano',f)\n",
    "        print(\"Estação do Ano vs \"+f+\" -> \"+str(corr))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "df1 = open_sheet('transformado_10000_sample.xlsx')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estação do Ano vs Hora -> 0.20295023708216434\n",
      "Estação do Ano vs Velocidade geral -> 0.004860950956620791\n",
      "Estação do Ano vs Velocidade local -> 0.0\n",
      "Estação do Ano vs Dia da Semana -> 0.004405346880863973\n",
      "Estação do Ano vs Num. Mortos a 30 dias -> 0.0\n",
      "Estação do Ano vs Num. Feridos graves a 30 dias -> 0.0030214432551221382\n",
      "Estação do Ano vs Num. Feridos ligeiros a 30 dias -> 0.010549444566889502\n",
      "Estação do Ano vs Características Tecnicas1 -> 0.017960874576118436\n",
      "Estação do Ano vs Cond Aderência -> 0.13741699644623548\n",
      "Estação do Ano vs NUTS II -> 0.028096317268941302\n",
      "Estação do Ano vs Tipos Vias -> 0.020182762711488694\n",
      "Estação do Ano vs Estado Conservação -> 0.0\n",
      "Estação do Ano vs Factores Atmosféricos -> 0.1375148813205754\n",
      "Estação do Ano vs Reg Circulação1 -> 0.0\n",
      "Estação do Ano vs Intersecção Vias -> 0.017944609536251047\n",
      "Estação do Ano vs Localizações -> 0.01241975779899108\n",
      "Estação do Ano vs Luminosidade -> 0.10203885942128045\n",
      "Estação do Ano vs Marca Via -> 0.014795298433675042\n",
      "Estação do Ano vs Natureza -> 0.01867914998101885\n",
      "Estação do Ano vs Tipo Piso -> 0.008360648535261538\n",
      "Estação do Ano vs Traçado 1 -> 0.0\n",
      "Estação do Ano vs Traçado 2 -> 0.005077478230050142\n",
      "Estação do Ano vs Traçado 3 -> 0.013188170565179026\n",
      "Estação do Ano vs Traçado 4 -> 0.0\n",
      "Estação do Ano vs Via Trânsito -> 0.008726638217362026\n"
     ]
    }
   ],
   "source": [
    "calculate_correlations(df1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "data": {
      "text/plain": "50.0     7406\n90.0     1535\n120.0     535\n80.0      158\n70.0      153\n100.0     122\n40.0       62\n30.0       44\n60.0       26\n20.0       11\n10.0        3\n0.0         1\n110.0       1\nName: Velocidade geral, dtype: int64"
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = open_sheet('final.xlsx')\n",
    "df_test['Velocidade geral'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
